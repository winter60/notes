# 引入



![图片来自网络](https://cdn.jsdelivr.net/gh/winter60/my_figurebed/data/20201017_image-20201017180217924.png)

（图片来自网络）

想象某人处于山上某个位置，要到达山底应该怎么走。首先应当从当前位置找到最陡峭的一个方向(梯度)，从该方向往下走一段距离，继续观察，最陡峭的某个方向，走一段举例，重复此过程就可能会到达(接近)山底。那么走多长的距离呢？如果走的距离比较短，那么就很频繁的判断这个陡峭的方向，非常耗时间。如果走了很长距离再来观察判断方向的话，那么就有可能偏离距离。所以，需要一个合适的距离来确保不那么耗费时间又能够走到山底。该方法正是使用了梯度下降的方法。那么什么是梯度下降法呢？

#  什么是梯度下降法(Gradient Descent，GD)

 **是一种基于搜索的最优化方法**， **目的是找到一组合适的参数，最小化一个目标函数**

## 什么是梯度？

梯度是一个向量，表示函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大。可以通过求导或者偏导(多元)，它的梯度可以定义为：
$$
\nabla J(\Theta)=\left\langle\frac{\partial J}{\partial \theta_{1}}, \frac{\partial J}{\partial \theta_{2}}, \frac{\partial J}{\partial \theta_{3}}\right\rangle
$$






![image-20201017212200741](https://cdn.jsdelivr.net/gh/winter60/my_figurebed/data/20201017_image-20201017212200741.png)


$$
\Theta^{i+1}=\Theta^{i}-\eta \nabla J(\Theta)
$$
J是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点，也就是山底。首先我们先确定前进的方向，也就是梯度的反向，然后走一段距离的步长，也就是η，走完这个段步长，就到达了Θ1这个点！

η称为学习率(learning rate)， η的取值影响获得最优解的速度， η取值不合适，甚至得不到最优解， η是梯度下降法的一个超参数

**梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向**







![image-20201017211738792](https://cdn.jsdelivr.net/gh/winter60/my_figurebed/data/20201017_image-20201017211738792.png)

加入山是长上图这个样子，那么从山上某一处出发，有可能 得到的是一个局部最低的地方。

问题：得到了局部最优解 并不是全局最优解 ？

解决方法：多次运行，随机化初始点。

想象有多个人从不同位置出发，那么才可能会有人到达的是山底。

# 梯度下降法的局限性

- 初值敏感，变量越多越敏感，不同的初值可能收敛到不同的极值点
- 学习率敏感，可动态改变学习率
- 无法完全保证取得的是全局最值

# 举例：[代码实现 梯度下降法](https://github.com/winter60/notes/blob/master/人工智能/梯度下降法/用梯度下降算法求函数最小值.py)

#  延伸----常见的梯度下降法

- Batch Gradient Descent（**BGD**，批量梯度下降）

> **批量梯度下降法**是最原始的形式，它是指在**每一次迭代时**使用**所有样本**来进行梯度的更新。

- Stochastic Gradient Descent（**SGD**，随机梯度下降）

> 随机梯度下降算法只随机抽取**一个**样本进行梯度计算，由于每次梯度下降迭代只计算一个样本的梯度，因此运算时间比小批量样本梯度下降算法还要少很多，但由于训练的数据量太小（只有一个），因此下降路径很容易受到训练数据自身噪音的影响，而且不一定朝着收敛的方向。

- Mini-Batch Gradient Descent（**MBGD**，小批量梯度下降）

> 是对批量梯度下降以及随机梯度下降的一个折中办法。其思想是：**每次迭代** 使用 ** batch_size** 个样本来对参数进行更新。

#  梯度下降法的应用场景

- 梯度下降法求解线性回归

- 梯度下降法求解逻辑回归

- 神经网络

  



参考链接：

[https://www.jianshu.com/p/c7e642877b0e](https://www.jianshu.com/p/c7e642877b0e)

[https://www.cnblogs.com/lliuye/p/9451903.html](https://www.cnblogs.com/lliuye/p/9451903.html)